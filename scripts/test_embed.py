"""
æµ‹è¯• bge-large-zh-v1.5 embedding æ¨¡å‹
æ³¨æ„ï¼šæ­¤è„šæœ¬ä½¿ç”¨å·²ä¸‹è½½çš„æ¨¡å‹ï¼Œä¸ä¼šé‡æ–°ä¸‹è½½
"""
import os
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app.embedder import create_embedder
import numpy as np

def main():
    print("=" * 70)
    print("æµ‹è¯• bge-large-zh-v1.5 æ¨¡å‹")
    print("=" * 70)
    print("\næ³¨æ„ï¼šæ­¤è„šæœ¬ä½¿ç”¨å·²ç¼“å­˜çš„æ¨¡å‹ï¼Œä¸ä¼šé‡æ–°ä¸‹è½½")
    print("å¦‚æœæ¨¡å‹æœªä¸‹è½½ï¼Œè¯·å…ˆè¿è¡Œ: python scripts/download_model.py\n")
    
    try:
        # åˆ›å»º embedderï¼ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹ï¼Œé¿å…é‡å¤ä¸‹è½½ï¼‰
        print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
        
        # æ„å»ºæœ¬åœ°æ¨¡å‹ç¼“å­˜è·¯å¾„
        model_cache_path = os.path.join(
            os.path.expanduser("~"),
            ".cache",
            "huggingface",
            "hub",
            "models--BAAI--bge-large-zh-v1.5",
            "snapshots"
        )
        
        # æ£€æŸ¥æœ¬åœ°ç¼“å­˜æ˜¯å¦å­˜åœ¨
        if os.path.exists(model_cache_path):
            # è·å–æœ€æ–°çš„snapshotç›®å½•
            snapshots = [d for d in os.listdir(model_cache_path) if os.path.isdir(os.path.join(model_cache_path, d))]
            if snapshots:
                # ä½¿ç”¨æœ€æ–°çš„snapshot
                latest_snapshot = sorted(snapshots)[-1]
                local_model_path = os.path.join(model_cache_path, latest_snapshot)
                print(f"âœ“ æ‰¾åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹: {local_model_path}")
                
                # ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½ï¼Œå®Œå…¨é¿å…ç½‘ç»œè¯·æ±‚
                embedder = create_embedder(model_path=local_model_path)
            else:
                raise FileNotFoundError("æ¨¡å‹ç¼“å­˜ç›®å½•å­˜åœ¨ä½†ä¸ºç©º")
        else:
            # å¦‚æœæœ¬åœ°æ²¡æœ‰ç¼“å­˜ï¼Œæç¤ºç”¨æˆ·å…ˆä¸‹è½½
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ç¼“å­˜ï¼\n"
                f"è¯·å…ˆè¿è¡Œ: python scripts/download_model.py\n"
                f"é¢„æœŸè·¯å¾„: {model_cache_path}"
            )
        
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼ï¼ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€è”ç½‘ï¼‰")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        print("\næ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
        info = embedder.get_model_info()
        for key, value in info.items():
            print(f"  â€¢ {key}: {value}")
        
        # æµ‹è¯•æ–‡æœ¬
        print("\n" + "=" * 70)
        print("æµ‹è¯•ä¿é™©ç›¸å…³æ–‡æœ¬ç¼–ç ")
        print("=" * 70)
        
        documents = [
            "æ„å¤–ä¼¤å®³ä¿é™©ç†èµ”æµç¨‹è¯´æ˜",
            "é‡å¤§ç–¾ç—…ä¿é™©æ¡æ¬¾è¯¦è§£",
            "è½¦é™©ç†èµ”æ‰€éœ€ææ–™æ¸…å•",
            "äººå¯¿ä¿é™©æŠ•ä¿é¡»çŸ¥",
            "åŒ»ç–—ä¿é™©æŠ¥é”€èŒƒå›´ä»‹ç»"
        ]
        
        queries = [
            "å¦‚ä½•ç”³è¯·æ„å¤–é™©ç†èµ”ï¼Ÿ",
            "é‡ç–¾é™©åŒ…å«å“ªäº›ç–¾ç—…ï¼Ÿ",
            "è½¦é™©éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"
        ]
        
        # ç¼–ç æ–‡æ¡£
        print("\nğŸ“„ ç¼–ç æ–‡æ¡£...")
        doc_embeddings = embedder.encode_documents(
            documents, 
            show_progress_bar=False
        )
        print(f"âœ“ æ–‡æ¡£å‘é‡å½¢çŠ¶: {doc_embeddings.shape}")
        print(f"  - æ–‡æ¡£æ•°é‡: {len(documents)}")
        print(f"  - å‘é‡ç»´åº¦: {doc_embeddings.shape[1]}")
        
        # è¯¦ç»†å±•ç¤ºæ¯ä¸ªæ–‡æ¡£çš„åŸæ–‡å’Œembeddingå‘é‡
        print("\n" + "=" * 70)
        print("æ–‡æ¡£è¯¦ç»†ä¿¡æ¯ï¼ˆåŸæ–‡ â†’ Embeddingå‘é‡ï¼‰")
        print("=" * 70)
        
        for i, doc in enumerate(documents):
            print(f"\nğŸ“„ æ–‡æ¡£ {i+1}:")
            print(f"  åŸæ–‡: \"{doc}\"")
            print(f"  å‘é‡ç»´åº¦: {doc_embeddings.shape[1]}")
            print(f"  å‘é‡å‰20ä¸ªå€¼: {doc_embeddings[i][:20]}")
            print(f"  å‘é‡ç»Ÿè®¡:")
            print(f"    - æœ€å¤§å€¼: {np.max(doc_embeddings[i]):.6f}")
            print(f"    - æœ€å°å€¼: {np.min(doc_embeddings[i]):.6f}")
            print(f"    - å‡å€¼: {np.mean(doc_embeddings[i]):.6f}")
            print(f"    - æ ‡å‡†å·®: {np.std(doc_embeddings[i]):.6f}")
            print(f"    - L2èŒƒæ•°: {np.linalg.norm(doc_embeddings[i]):.6f}")
        
        # ç¼–ç æŸ¥è¯¢
        print("\n" + "=" * 70)
        print("ğŸ” ç¼–ç æŸ¥è¯¢...")
        print("=" * 70)
        query_embeddings = embedder.encode_queries(
            queries,
            show_progress_bar=False
        )
        print(f"\nâœ“ æŸ¥è¯¢å‘é‡å½¢çŠ¶: {query_embeddings.shape}")
        print(f"  - æŸ¥è¯¢æ•°é‡: {len(queries)}")
        print(f"  - å‘é‡ç»´åº¦: {query_embeddings.shape[1]}")
        
        # è¯¦ç»†å±•ç¤ºæ¯ä¸ªæŸ¥è¯¢çš„åŸæ–‡å’Œembeddingå‘é‡
        print("\n" + "=" * 70)
        print("æŸ¥è¯¢è¯¦ç»†ä¿¡æ¯ï¼ˆåŸæ–‡ â†’ Embeddingå‘é‡ï¼‰")
        print("=" * 70)
        
        for i, query in enumerate(queries):
            print(f"\nğŸ” æŸ¥è¯¢ {i+1}:")
            print(f"  åŸæ–‡: \"{query}\"")
            print(f"  å‘é‡ç»´åº¦: {query_embeddings.shape[1]}")
            print(f"  å‘é‡å‰20ä¸ªå€¼: {query_embeddings[i][:20]}")
            print(f"  å‘é‡ç»Ÿè®¡:")
            print(f"    - æœ€å¤§å€¼: {np.max(query_embeddings[i]):.6f}")
            print(f"    - æœ€å°å€¼: {np.min(query_embeddings[i]):.6f}")
            print(f"    - å‡å€¼: {np.mean(query_embeddings[i]):.6f}")
            print(f"    - æ ‡å‡†å·®: {np.std(query_embeddings[i]):.6f}")
            print(f"    - L2èŒƒæ•°: {np.linalg.norm(query_embeddings[i]):.6f}")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        print("\nğŸ“Š è®¡ç®—ç›¸ä¼¼åº¦...")
        similarities = embedder.similarity(query_embeddings, doc_embeddings)
        
        print("\n" + "=" * 70)
        print("æŸ¥è¯¢-æ–‡æ¡£ç›¸ä¼¼åº¦ç»“æœ")
        print("=" * 70)
        
        for i, query in enumerate(queries):
            print(f"\nğŸ” æŸ¥è¯¢ {i+1}: {query}")
            print("-" * 70)
            
            # è·å–æ’åºåçš„ç´¢å¼•ï¼ˆä»é«˜åˆ°ä½ï¼‰
            sorted_indices = np.argsort(similarities[i])[::-1]
            
            for rank, j in enumerate(sorted_indices, 1):
                similarity_score = similarities[i][j]
                print(f"  {rank}. [ç›¸ä¼¼åº¦: {similarity_score:.4f}] {documents[j]}")
            
            # æ ‡è®°æœ€ç›¸å…³çš„æ–‡æ¡£
            most_similar_idx = sorted_indices[0]
            print(f"\n  âœ“ æœ€ç›¸å…³æ–‡æ¡£: {documents[most_similar_idx]}")
            print(f"    ç›¸ä¼¼åº¦åˆ†æ•°: {similarities[i][most_similar_idx]:.4f}")
        
        # é¢å¤–æµ‹è¯•ï¼šå•ä¸ªæ–‡æœ¬ç¼–ç 
        print("\n" + "=" * 70)
        print("æµ‹è¯•å•ä¸ªæ–‡æœ¬ç¼–ç ")
        print("=" * 70)
        
        single_text = "ä¿é™©ç†èµ”éœ€è¦å“ªäº›ææ–™ï¼Ÿ"
        print(f"\næ–‡æœ¬: {single_text}")
        
        single_embedding = embedder.encode(single_text, show_progress_bar=False)
        print(f"âœ“ å‘é‡å½¢çŠ¶: {single_embedding.shape}")
        print(f"  å‘é‡å‰5ä¸ªå€¼: {single_embedding[0][:5]}")
        
        # éªŒè¯å‘é‡å½’ä¸€åŒ–
        norm = np.linalg.norm(single_embedding[0])
        print(f"  å‘é‡èŒƒæ•°: {norm:.6f} (åº”æ¥è¿‘1.0ï¼Œè¡¨ç¤ºå·²å½’ä¸€åŒ–)")
        
        print("\n" + "=" * 70)
        print("âœ“ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 70)
        print("\næç¤ºï¼š")
        print("  â€¢ æ¨¡å‹å·²æˆåŠŸåŠ è½½å¹¶æµ‹è¯•")
        print("  â€¢ ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: -1 åˆ° 1 (è¶Šæ¥è¿‘1è¶Šç›¸ä¼¼)")
        print("  â€¢ å‘é‡å·²å½’ä¸€åŒ–ï¼Œé€‚åˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—")
        
        return True
        
    except Exception as e:
        print(f"\nâœ— é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        print("\næç¤ºï¼šå¦‚æœæ¨¡å‹æœªä¸‹è½½ï¼Œè¯·å…ˆè¿è¡Œ: python scripts/download_model.py")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
