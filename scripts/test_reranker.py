"""
æµ‹è¯• Reranker æ¨¡å—
åŒ…å«faisså‘é‡æ£€ç´¢å’Œbge-reranker-largeé‡æ’åºåŠŸèƒ½
"""
import os
import sys
import json
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app.embedder import create_embedder
from app.reranker import create_reranker
import numpy as np


def find_local_model(model_name: str, model_type: str = "embedder"):
    """
    æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹è·¯å¾„
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼ˆå¦‚ "BAAI/bge-large-zh-v1.5"ï¼‰
        model_type: æ¨¡å‹ç±»å‹ ("embedder" æˆ– "reranker")
    
    Returns:
        æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–None
    """
    cache_dir = os.path.join(
        os.path.expanduser("~"),
        ".cache",
        "huggingface",
        "hub"
    )
    
    # å°†æ¨¡å‹åç§°è½¬æ¢ä¸ºç›®å½•å
    model_dir_name = model_name.replace("/", "--")
    model_path = os.path.join(cache_dir, f"models--{model_dir_name}", "snapshots")
    
    if os.path.exists(model_path):
        snapshots = [d for d in os.listdir(model_path) 
                    if os.path.isdir(os.path.join(model_path, d))]
        if snapshots:
            latest_snapshot = sorted(snapshots)[-1]
            return os.path.join(model_path, latest_snapshot)
    
    return None


def load_chunks_from_data_dir(data_dir: str = "data/chunks"):
    """
    ä»data/chunksç›®å½•åŠ è½½æ‰€æœ‰chunksæ–‡ä»¶
    
    Args:
        data_dir: chunksç›®å½•è·¯å¾„
        
    Returns:
        List of (file_path, chunks) tuples
    """
    data_path = Path(data_dir)
    if not data_path.exists():
        print(f"è­¦å‘Š: {data_dir} ç›®å½•ä¸å­˜åœ¨")
        return []
    
    chunks_files = list(data_path.glob("*_chunks.json"))
    print(f"æ‰¾åˆ° {len(chunks_files)} ä¸ªchunksæ–‡ä»¶")
    
    all_chunks = []
    for chunks_file in chunks_files:
        print(f"\nåŠ è½½: {chunks_file.name}")
        try:
            from app.reranker import Reranker
            from app.embedder import create_embedder
            
            # ä¸´æ—¶åˆ›å»ºrerankeræ¥åŠ è½½chunks
            embedder = create_embedder()
            reranker = create_reranker(embedder)
            chunks = reranker.load_chunks_from_json(chunks_file)
            all_chunks.extend(chunks)
            print(f"  âœ“ åŠ è½½äº† {len(chunks)} ä¸ªchunks")
        except Exception as e:
            print(f"  âœ— åŠ è½½å¤±è´¥: {e}")
            continue
    
    return all_chunks


def main():
    print("=" * 70)
    print("æµ‹è¯• Reranker æ¨¡å—")
    print("=" * 70)
    print("\nåŠŸèƒ½æµ‹è¯•ï¼š")
    print("  1. Faisså‘é‡æ£€ç´¢ (Ranking)")
    print("  2. BGE-Rerankeré‡æ’åº (Reranking)")
    print("  3. å®Œæ•´æ£€ç´¢æµç¨‹")
    print("=" * 70)
    
    try:
        # 1. åŠ è½½embedderæ¨¡å‹
        print("\nğŸ“¦ æ­¥éª¤1: åŠ è½½Embedderæ¨¡å‹...")
        embedder_model_path = find_local_model("BAAI/bge-large-zh-v1.5", "embedder")
        if embedder_model_path:
            print(f"âœ“ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {embedder_model_path}")
            embedder = create_embedder(model_path=embedder_model_path)
        else:
            print("âš  æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå°†ä»ç½‘ç»œä¸‹è½½...")
            embedder = create_embedder()
        print("âœ“ EmbedderåŠ è½½æˆåŠŸ")
        
        # 2. åŠ è½½rerankeræ¨¡å‹
        print("\nğŸ“¦ æ­¥éª¤2: åŠ è½½Rerankeræ¨¡å‹...")
        reranker_model_path = find_local_model("BAAI/bge-reranker-large", "reranker")
        if reranker_model_path:
            print(f"âœ“ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {reranker_model_path}")
            reranker = create_reranker(
                embedder,
                reranker_model_path=reranker_model_path
            )
        else:
            print("âš  æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ï¼Œå°†ä»ç½‘ç»œä¸‹è½½...")
            print("  æç¤º: é¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
            reranker = create_reranker(embedder)
        print("âœ“ RerankeråŠ è½½æˆåŠŸ")
        
        # 3. åŠ è½½chunksæ•°æ®
        print("\nğŸ“¦ æ­¥éª¤3: åŠ è½½chunksæ•°æ®...")
        chunks = load_chunks_from_data_dir("data/chunks")
        
        if not chunks:
            print("\nâš  æœªæ‰¾åˆ°chunksæ•°æ®ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®...")
            # ä½¿ç”¨æµ‹è¯•æ•°æ®
            from app.chunker import Chunk, ChunkMetadata
            test_texts = [
                "æ„å¤–ä¼¤å®³ä¿é™©ç†èµ”æµç¨‹è¯´æ˜ï¼Œéœ€è¦å‡†å¤‡èº«ä»½è¯ã€åŒ»ç–—è¯æ˜ç­‰ææ–™",
                "é‡å¤§ç–¾ç—…ä¿é™©æ¡æ¬¾è¯¦è§£ï¼ŒåŒ…å«30ç§é‡å¤§ç–¾ç—…çš„ä¿éšœèŒƒå›´",
                "è½¦é™©ç†èµ”æ‰€éœ€ææ–™æ¸…å•ï¼šé©¾é©¶è¯ã€è¡Œé©¶è¯ã€äº‹æ•…è¯æ˜ç­‰",
                "äººå¯¿ä¿é™©æŠ•ä¿é¡»çŸ¥ï¼Œå¹´é¾„é™åˆ¶å’Œå¥åº·å‘ŠçŸ¥è¦æ±‚",
                "åŒ»ç–—ä¿é™©æŠ¥é”€èŒƒå›´ä»‹ç»ï¼ŒåŒ…æ‹¬é—¨è¯Šå’Œä½é™¢è´¹ç”¨"
            ]
            chunks = []
            for i, text in enumerate(test_texts):
                metadata = ChunkMetadata(
                    chunk_id=f"test_{i}",
                    chunk_type="paragraph",
                    section_path=["æµ‹è¯•ç« èŠ‚"],
                    heading_level=1,
                    char_count=len(text),
                    image_refs=[],
                    source_file="test.md"
                )
                chunk = Chunk(chunk_id=f"test_{i}", text=text, metadata=metadata)
                chunks.append(chunk)
        
        print(f"âœ“ æ€»å…± {len(chunks)} ä¸ªchunks")
        
        # 4. æ„å»ºfaissç´¢å¼•
        print("\nğŸ“¦ æ­¥éª¤4: æ„å»ºFaissç´¢å¼•...")
        reranker.build_index(chunks, index_type="flat")
        print("âœ“ ç´¢å¼•æ„å»ºå®Œæˆ")
        
        # æ˜¾ç¤ºç´¢å¼•ä¿¡æ¯
        index_info = reranker.get_index_info()
        print("\nç´¢å¼•ä¿¡æ¯:")
        for key, value in index_info.items():
            print(f"  â€¢ {key}: {value}")
        
        # 5. æµ‹è¯•æŸ¥è¯¢
        print("\n" + "=" * 70)
        print("ğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½")
        print("=" * 70)
        
        test_queries = [
            "å¦‚ä½•ç”³è¯·æ„å¤–é™©ç†èµ”ï¼Ÿ",
            "é‡ç–¾é™©åŒ…å«å“ªäº›ç–¾ç—…ï¼Ÿ",
            "è½¦é™©éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ",
            "äº’è”ç½‘ä¿é™©çš„å‘å±•è¶‹åŠ¿"
        ]
        
        for query_idx, query in enumerate(test_queries, 1):
            print(f"\n{'='*70}")
            print(f"æŸ¥è¯¢ {query_idx}: {query}")
            print("=" * 70)
            
            # æ‰§è¡Œå®Œæ•´æ£€ç´¢æµç¨‹
            results = reranker.search(
                query,
                rank_top_k=20,
                rerank_top_k=5,
                use_rerank=True
            )
            
            print(f"\nâœ“ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ:\n")
            
            for rank, (chunk, final_score, info) in enumerate(results, 1):
                print(f"ã€æ’å {rank}ã€‘åˆ†æ•°: {final_score:.4f}")
                print(f"  Rankingåˆ†æ•°: {info['rank_score']:.4f}")
                print(f"  Rerankåˆ†æ•°: {info['rerank_score']:.4f}")
                
                # æ˜¾ç¤ºchunkä¿¡æ¯
                text_preview = chunk.text[:150] + "..." if len(chunk.text) > 150 else chunk.text
                print(f"  æ–‡æœ¬é¢„è§ˆ: {text_preview}")
                
                if 'metadata' in info:
                    meta = info['metadata']
                    print(f"  ç« èŠ‚è·¯å¾„: {' > '.join(meta.get('section_path', []))}")
                    print(f"  ç±»å‹: {meta.get('chunk_type', 'unknown')}")
                    if meta.get('has_table'):
                        print(f"  âœ“ åŒ…å«è¡¨æ ¼")
                    if meta.get('has_list'):
                        print(f"  âœ“ åŒ…å«åˆ—è¡¨")
                print()
        
        # 6. å¯¹æ¯”æµ‹è¯•ï¼šä»…ranking vs ranking+reranking
        print("\n" + "=" * 70)
        print("ğŸ“Š å¯¹æ¯”æµ‹è¯•: ä»…Ranking vs Ranking+Reranking")
        print("=" * 70)
        
        query = "äº’è”ç½‘ä¿é™©çš„å‘å±•è¶‹åŠ¿"
        print(f"\næŸ¥è¯¢: {query}\n")
        
        # ä»…ranking
        print("ã€ä»…Rankingç»“æœã€‘")
        rank_only_results = reranker.search(
            query,
            rank_top_k=5,
            rerank_top_k=5,
            use_rerank=False
        )
        for i, (chunk, score, info) in enumerate(rank_only_results, 1):
            print(f"  {i}. [åˆ†æ•°: {score:.4f}] {chunk.text[:80]}...")
        
        # ranking + reranking
        print("\nã€Ranking + Rerankingç»“æœã€‘")
        rerank_results = reranker.search(
            query,
            rank_top_k=20,
            rerank_top_k=5,
            use_rerank=True
        )
        for i, (chunk, score, info) in enumerate(rerank_results, 1):
            print(f"  {i}. [åˆ†æ•°: {score:.4f}] {chunk.text[:80]}...")
            print(f"     (Ranking: {info['rank_score']:.4f}, Rerank: {info['rerank_score']:.4f})")
        
        print("\n" + "=" * 70)
        print("âœ“ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 70)
        print("\næç¤ºï¼š")
        print("  â€¢ Faissç´¢å¼•å·²æ„å»ºï¼Œå¯ä»¥å¿«é€Ÿè¿›è¡Œå‘é‡æ£€ç´¢")
        print("  â€¢ Rerankeræ¨¡å‹å¯ä»¥å¯¹ç»“æœè¿›è¡Œç²¾ç»†æ’åº")
        print("  â€¢ ç»“åˆmetadataåŠ æƒå¯ä»¥æå‡ä¿é™©æ¡æ¬¾æ£€ç´¢çš„å‡†ç¡®æ€§")
        
        return True
        
    except Exception as e:
        print(f"\nâœ— é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        print("\næç¤ºï¼š")
        print("  â€¢ ç¡®ä¿å·²å®‰è£…faiss: pip install faiss-cpu æˆ– pip install faiss-gpu")
        print("  â€¢ ç¡®ä¿å·²å®‰è£…transformers: pip install transformers")
        print("  â€¢ å¦‚æœæ¨¡å‹æœªä¸‹è½½ï¼Œé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
